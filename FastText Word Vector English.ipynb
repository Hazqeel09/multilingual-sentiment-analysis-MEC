{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import tokenize\n",
    "from gensim import utils\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.models import FastText\n",
    "from gensim.models.fasttext import load_facebook_vectors, load_facebook_model, save_facebook_model\n",
    "from gensim.test.utils import common_texts\n",
    "import numpy as np\n",
    "import fasttext\n",
    "import fasttext.util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = []\n",
    "with open('Data/pos_e.txt','r',encoding='utf-8') as pos_file:\n",
    "    with open('Data/neg_e.txt','r',encoding='utf-8') as neg_file:\n",
    "            for line in pos_file:\n",
    "                splitted = line.split(',')\n",
    "                text = splitted[0].split(\" \")\n",
    "                merged.append(text)\n",
    "                \n",
    "            for line in neg_file:\n",
    "                splitted = line.split(',')\n",
    "                text = splitted[0].split(\" \")\n",
    "                merged.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['i', 'love', 'u', 'guys', 'r', 'the', 'best'],\n",
       " ['im',\n",
       "  'meeting',\n",
       "  'up',\n",
       "  'with',\n",
       "  'one',\n",
       "  'of',\n",
       "  'my',\n",
       "  'besties',\n",
       "  'tonight',\n",
       "  'can',\n",
       "  'not',\n",
       "  'wait',\n",
       "  'girl',\n",
       "  'talk'],\n",
       " ['thanks',\n",
       "  'for',\n",
       "  'the',\n",
       "  'twitter',\n",
       "  'add',\n",
       "  'sunisa',\n",
       "  'i',\n",
       "  'got',\n",
       "  'to',\n",
       "  'meet',\n",
       "  'you',\n",
       "  'once',\n",
       "  'at',\n",
       "  'a',\n",
       "  'hin',\n",
       "  'show',\n",
       "  'here',\n",
       "  'in',\n",
       "  'the',\n",
       "  'dc',\n",
       "  'area',\n",
       "  'and',\n",
       "  'you',\n",
       "  'were',\n",
       "  'a',\n",
       "  'sweetheart'],\n",
       " ['being',\n",
       "  'sick',\n",
       "  'can',\n",
       "  'be',\n",
       "  'really',\n",
       "  'cheap',\n",
       "  'when',\n",
       "  'it',\n",
       "  'hurts',\n",
       "  'too',\n",
       "  'much',\n",
       "  'to',\n",
       "  'eat',\n",
       "  'real',\n",
       "  'food',\n",
       "  'plus',\n",
       "  'your',\n",
       "  'friends',\n",
       "  'make',\n",
       "  'you',\n",
       "  'soup'],\n",
       " ['he', 'has', 'that', 'effect', 'on', 'everyone']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "cap_path = datapath(\"ccen300bin\\ccen300.bin\")\n",
    "ft = fasttext.load_model(cap_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext.util.reduce_model(ft, 150)\n",
    "ft.get_dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_path = datapath(\"ccen150bin\\ccen150.bin\")\n",
    "ft.save_model(cap_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.get_dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\nUse KeyedVector's .key_to_index dict, .index_to_key list, and methods .get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\nSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-dd545e9c1179>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcap_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatapath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ccen150bin\\ccen150.bin\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfb_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_facebook_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcap_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfb_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\AllAnaconda\\envs\\twtAnalytics\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mvocab\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    646\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 648\u001b[1;33m         raise AttributeError(\n\u001b[0m\u001b[0;32m    649\u001b[0m             \u001b[1;34m\"The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m             \u001b[1;34m\"Use KeyedVector's .key_to_index dict, .index_to_key list, and methods \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\nUse KeyedVector's .key_to_index dict, .index_to_key list, and methods .get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\nSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4"
     ]
    }
   ],
   "source": [
    "cap_path = datapath(\"ccen150bin\\ccen150.bin\")\n",
    "fb_model = load_facebook_model(cap_path)\n",
    "len(fb_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fb_model.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_model.build_vocab(merged, update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126383558, 518174295)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fb_model.train(merged, total_examples=len(merged), epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_path = datapath(\"ccen150bin\\ccen150_2.bin\")\n",
    "save_facebook_model(fb_model,cap_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2010436"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fb_model.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2156311"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# original BIN model loading\n",
    "f = fasttext.load_model(cap_path)\n",
    "lines=[]\n",
    "\n",
    "# get all words from model\n",
    "words = f.get_words()\n",
    "\n",
    "with open('Data\\FastText\\ccen150vec\\ccen150.vec','w') as file_out:\n",
    "    \n",
    "    # the first line must contain number of total words and vector dimension\n",
    "    file_out.write(str(len(words)) + \" \" + str(f.get_dimension()) + \"\\n\")\n",
    "\n",
    "    # line by line, you append vectors to VEC file\n",
    "    for w in words:\n",
    "        v = f.get_word_vector(w)\n",
    "        vstr = \"\"\n",
    "        for vi in v:\n",
    "            vstr += \" \" + str(vi)\n",
    "        try:\n",
    "            file_out.write(w + vstr+'\\n')\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
